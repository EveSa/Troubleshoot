---
---
# The History of Neural Networks

c.f. La revanche des neurones

Historiquement : calculer des portes logiques de bases (OR, AND, â€¦)

# How it works

$$
w_0*x_0 + b_0 = output
$$

Les facteurs $w_0$ et $b_0$ sont re dÃ©terminÃ© tout au long de lâ€™entraÃ®nement pour parvenir Ã  prÃ©dire lâ€™output de faÃ§on correcte (face aux donnÃ©es dâ€™entraÃ®nement)

$x_0$ est la donnÃ©e dâ€™entrÃ©e (un mot, un point, un document)

**Mais comment reprÃ©senter un mot sous forme numÃ©rique ?**
On peut donner Ã  un mot un vecteur dans un espace Ã  n dimension.

ReprÃ©senter une droite avec les donnÃ©es de dÃ©part peut ne pas Ãªtre suffisant pour rÃ©soudre notre problÃ¨me. Dans ce cas, on peut utiliser plusieurs couche de neurones : 

- Les premiers neurones calculent une nouvelle reprÃ©sentation de lâ€™entrÃ©e
- Les seconds neurones calculent une reprÃ©sentation issue de la reprÃ©sentation modifiÃ©e
- â€¦
- Les derniers neurones calculent une reprÃ©sentation qui rÃ©sout le problÃ¨me donnÃ©

On ne sait jamais combien de couche de neurone est nÃ©cessaire Ã  la reprÃ©sentation dâ€™un problÃ¨me

### En NLP

On a un mot.

On va essayer de le reprÃ©senter avec des caratÃ©ristiques numÃ©riques parceque les ordinateurs ne comprennent pas les mots.

Pour Ã§a on va prendre un espace de dimension N avec N le nombre de caractÃ©ristique (*features*) que notre modÃ¨le va pouvoir reprÃ©senter.

On peut imaginer une caractÃ©ristique *genre* ou *nombre* par exemple

( en vÃ©ritÃ©, câ€™est pas du tout comme Ã§a que Ã§a se passe parceque les modÃ¨les choisissent des caractÃ©ristiques â€œcachÃ©esâ€ (*latente*) qui nâ€™ont pas Ã  voir avec la rÃ©alitÃ© linguistique )

Lâ€™objectif du modÃ¨le, Ã§a va Ãªtre de donner une valeur au mot par caractÃ©ristique : Ã  quel point ce mot il est *fÃ©minin-masculin,* Ã  quel point ce mot il est *singlier-pluriel*. Quand il a positionnÃ© le curseur de toutes les caractÃ©ristiques, il nous donne une suite de valeur (une valeur par caratÃ©ristique) : câ€™est le **vecteur** du mot dans lâ€™espace de dimension N quâ€™on a choisi au dÃ©part

### Comment un NN fait pour choisir les valeurs quâ€™il donne Ã  un mot ?

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/51bb4b15-01f5-4b17-8e78-4c910f77218d/a35f17e7-1937-4a7c-b249-b648037613c9/Untitled.png)

Un rÃ©seau de neurone va utiliser des **poids** pour positionner un Ã©lÃ©ment sur diffÃ©rentes caractÃ©ristiques. Mais pour donner la reprÃ©sentation finale (le vecteur qui reprÃ©sente notre mot), il va pouvoir passer par plusieurs Ã©tapes dâ€™abstraction (plusieurs couches de neurones). Câ€™est Ã  cause de ces plusieurs couches quâ€™on parle de â€œdeepâ€ ou â€œmultilayerâ€ neural networks

Dans le graphique ci dessus, suivons une seule des entrÃ©es proposÃ©e : lâ€™entrÃ©e â€œÃ©toile de merâ€. En fait, notre Ã©toile de mer, elle ressemble plutÃ´t Ã  Ã§a 

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/51bb4b15-01f5-4b17-8e78-4c910f77218d/4584e4df-981f-450f-9623-d1301b0bfdcb/Untitled.png)

Ici, le rÃ©seau donne un poids important Ã  la forme de lâ€™entrÃ©e vers la forme â€œÃ©toile de merâ€ et un poids important vers la texture â€œÃ©toile de merâ€. Si on avait plusieurs couche, on aurait pu imaginer que le modÃ¨le aurait dâ€™abord essayer de discriminer une forme dâ€™hexagone avant de raffiner sur une forme dâ€™Ã©toile de mer et une forme de â€œFranceâ€ par exemple.

### Quâ€™est ce quâ€™un neurone

pour un MLP

## Quâ€™est ce quâ€™un CRF ?

Conditionnal Random Field : modÃ¨le statistique qui reprÃ©sente le contexte adjacent par un graphe de dÃ©pendance. En NLP, on utilise souvent un graphe linÃ©aire (pour modÃ©liser la sÃ©quentialitÃ©)

# Why is Explainability a Problem (XAI)

Because Deep Neural Networks are a blackbox it is unpredictable in unknown situation. Deep Neurons have bad extrapolation capability which makes them especially unpredicatable. As it is impossible to cover every possibility in a dataset, models will have to extrapolate on unseen data.

## Adversial Attack

adversial machine learning ?

## Explanability ideas

Comment imposer le bon biais inductif au modÃ¨le :

- avec lâ€™Ã©quivariance

# Graph Neural Networks

Les rÃ©seaux de neurones sur graphes (ou rÃ©seau de neurones en graphes/rÃ©seaux de neurones graphiques)

<aside>
ğŸ’¡ Deep Learning GeomÃ©trique : trouver un cadre mathÃ©matique commun pour unifier

</aside>

# What is model perplexity ?

Une mÃ©trique pour les modÃ¨les de langues autorÃ©gressifs https://huggingface.co/docs/transformers/perplexity

# LLMs

RLHF : Reinforcement Learning with Human Feedback

# Adaptation de modÃ¨les

## Fine-tuning

## RLHF: Reinforcement Learning From Human Feedback

## ICL: In Context Learning

## MAML: [Model Agnostic Meta Learning](https://interactive-maml.github.io/maml.html)

MAML propose une solution pour l'entraÃ®nement de modÃ¨le avec des trÃ¨s petit jeux de donnÃ©es. L'objectif est d'obtenir une reprÃ©sentation - des poids de modÃ¨les - qui soient le plus proche possible d'un grand nombre de tÃ¢ches afin que leur adaptation ne requiÃ¨re qu'un "petit" *fine-tuning*.

L'objectif n'est pas d'entraÃ®ner un modÃ¨le sur une tÃ¢che mais d'**entraÃ®ner un modÃ¨le Ã  apprendre**.

> â“ Est ce que l'objectif serait un modÃ¨le avec les plus petits vecteurs de tÃ¢ches â“



Model agnostic : la mÃ©thode est adaptable pour tous modÃ¨les utilisant une descente de gradiant.

Meta Learning : Apprendre au modÃ¨le Ã  apprendre (sur des petits jeu de donnÃ©es et sans *over-fitter*)